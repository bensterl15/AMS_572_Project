The second hypothesis analyzes which environmental factors are the best predictors of temperature in Salt Lake City. According to the EPA, higher temperature results in either more or less precipitation and higher frequency of storms\cite{epa_utah}. This study performs a multiple linear regression of temperature against minutes of sunlight, number of days with thunderstorms, and precipitation per month. In conjuction with the EPA article noted above, we also considered two key characteristics when deciding which parameters we would include in our study: 

\begin{itemize}
	\item linear relationship with temperature, and
	\item availability of data.
\end{itemize}

For example, we did not include total monthly snowfall or number of days with fog because they have too much missing data despite having a decent linear relationship. The parameter with the most significant linear relationship with temperature is, not suprisingly, minutes of sunlight. A major factor we had to consider here, however, was that sunlight data is only recorded from 1965 to 2004. Thus, in order to include this parameter in our analysis, we needed to restrict our study down to this range (roughly 479 total months, or observations). Additionally, we limited the data used in our study to months for which the data was available for all four parameters listed above. Therefore, when including temperature, number of days with thunderstorms, and precipitation in our study, our sample size decreased from 479 months to 321 months because at least one of the these parameters was missing data in the 479 months of data available between 1965 and 2004.

For each parameter identified above, we graphically examine its relation with temperature via a scatter plot with a line of best fit. As expected, there is a strong positive correlation between minutes of sunlight and temperature, as seen in Figure \ref{fig:temp_vs_sun}. Similarly, albeit not as strong, there also appears to be a positive correlation between number of days with thunderstorms and temperature, as seen in Figure \ref{fig:temp_vs_dthunderstorms}. Lastly, the correlation between precipitation and temperature is negative, as seen in Figure \ref{fig:temp_vs_precipitation}, which is expected in some regions as stated by the EPA \cite{epa_utah}.

As an additional preliminarly analysis, in order to obtain a strong multiple linear regression model to estimate temperature, we sought to use parameters that are not highly correlated with each other, as including additional variables that are highly correlated is more likely to simply increase model complexity as opposed to improve the model fit. Figure \ref{fig:correlation_plot}, which is a correlation matrix of the three independent parameters, suggests that the independent variables of sunlight, days with thunderstorms, and precipitation are not highly correlated, further supporting our decision to include them as parameters in our model.

At this point, we conducted the analysis on the selected paramters. Per Table \ref{tab:lin_regression}, we can see the the model has an adjusted $R^{2}$ of $0.7969 \approx$ 0.8, meaning that roughly 80.0\% of the variance in temperature can be explained by the three predictors. Using the coefficients from the table, we can estimate temperature as $\hat{T} = \beta_{0} + X_{1}\beta_{1} + X_{2}\beta_{2} + X_{3}\beta_{3}$, where indices 1, 2, and 3 reference minutes of sun, days with thunderstorms, and precipitation, respectively. Substituting $\beta$ values from Table \ref{tab:lin_regression}, $$\hat{T} \approx -5.26 + 1.04 \times 10^{-3}X_{1} + 0.84X_{2} - 4.80\times 10^{-2}X_{3}.$$

Now that we have completed our multiple linear regression analysis on the three selected parameters, we turn to a final model comparison analysis. Here, we conduct a best subset analysis to locate the best model at each model size, including 1, 2, and 3 parameters. The best subset selection process considers all $3 \choose k$ possibilities, where k is the number of parameters (k = 1, 2, 3). For each k, the best subset method will select the model with the lowest SSE. As can been seen in Table \ref{tab:optimal_selection}, the best models for k = 1, 2, and 3 are minutes of sun, minutes of sun + days with thunderstorms, and minutes of sun + days with thunderstorms + precipitation, respectively.

Now that we have our three best models at each k, we will calculate the following metrics for each model: 

\begin{itemize}
	\item adjusted $R^{2}$,
	\item AIC, and
	\item BIC.
\end{itemize}

The adjusted $R^{2}$ will measure what percentage of the variance in the model is explained by the parameters; this measure penalizes model complexity relative to $R^{2}$. Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) are both penalized-likelihood criteria, where the BIC penalizes model complexity a bit more than AIC. Overall, the best model of the three from Table \ref{tab:optimal_selection} will have the greatest adjusted $R^{2}$ and the lowest AIC and BIC values. Define: 

\begin{itemize}
	\item Model 1: Performs a regression against minutes of sunlight
	\item Model 2: Performs a regression against minutes of sunlight + days with thunderstorms
	\item Model 3: Performs a regression against minutes of sunlight + days with thunderstorms + precipitation
\end{itemize} 

Table \ref{tab:model_info} contains these values for each model. The full model, model 3, is the best overall model to choose to estimate temperature because it has the highest adjusted $R^{2}$ and lowest AIC and BIC values.

To demonstrate our results, let us consider the following example to predict the average monthly temperature of a new observation $Y^{*}$. Notationally, the following formula enables the calculation of a $(1-\alpha)$-level prediction interval for $Y^{*}$. $$Y^{*} \pm \hat{Y}^{*} + t_{n-(k+1),\alpha/2} s \sqrt{1+\textbf{x}^{*T}\textbf{V}\textbf{x}^{*}}$$ where $\hat{Y}^{*}$ is the estimate of $Y^{*}$, $t_{n-(k+1),\alpha/2}$ is the critical value, n is the number of observations (n = 321), k is the number of predictors (k = 3), $s$ is the estimate for $\sigma$, equivalent to $\sqrt{MSE}$, $\textbf{x}^{*}$ is matrix of predictor variables for the three parameters, and $\textbf{V} = (\textbf{X}^{T}\textbf{X})^{-1}$, where $\textbf{X}$ represents the matrix of the values of the predictor variables \cite{tamhane}.

Now, given a new month with 15,000 minutes of sunlight, 4 days with thunderstorms, and 35 millimeters of total precipitation, we can calculcate a 95\% prediction interval. To avoid extrapolation, the parameter figures above are all within the ranges of values observed for each parameter in the 321 oberservations analyzed. Utilizing the prediction interval with 95\% confidence, the average monthly temperature of this new month would be between $4.48^{\circ}$C and $19.63^{\circ}$C (with $\hat{Y}^{*} = 12.06^{\circ}$C).

To investigate the effects of missing data on the multiple linear regression, we removed 5\% of temperature observations, 5\% of sunlight observations, 5\% of thunderstorm observations, and 5\% of precipitation observations. We then ignored any data point for which at least one of these four observations was missing, resulting in a smaller sample size approximately 80\% of the original. The new adjusted $R^{2}$ is $0.797 \approx 0.8$, indicating that roughly 80\% of the variation in temperature can be explained by the three predictors. This is not appreciably different from the adjusted $R^{2}$ for the full data set from 1965 to 2004, which was also approximately 80\%. The new estimate for temperature is $$\hat{T} \approx -4.79 + 1.03 \times 10^{-3}X_{1} + 0.85X_{2} - 6.30\times 10^{-2}X_{3}.$$ See Table \ref{tab:lin_regression_missing_data} for the $\beta$ values and p-values for all three predictor variables in the missing data case. Table \ref{tab:model_info_missing_data} implies that Model 3 is once again optimal.
